{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jacobi Method Algorithm coded By John Lain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def jacobi(A, b, x0, iterations = 50, tol = 0.000001, true = None):\n",
    "    \"\"\"\n",
    "    Solves a system of linear equations using the Jacobi method\n",
    "    Expected inputs:\n",
    "    A: nxn matrix\n",
    "    b: column vector of length n\n",
    "    x0: initial guess for solution\n",
    "    tol: error between true and numerical solution\n",
    "    true: true solution\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    x = x0\n",
    "    d = np.diagonal(A)\n",
    "    LU = A - np.diag(d)\n",
    "    n = np.size(b)\n",
    "    if type(true) == np.ndarray:\n",
    "        while max(abs(true - x)) > tol:\n",
    "            count = count + 1\n",
    "            x = (1/d)*(b - LU@x)\n",
    "        print(f\"Number of iterations = {count}\")\n",
    "        return(x)\n",
    "    else:\n",
    "        for i in range(iterations):\n",
    "            x = (1/d)*(b - LU@x)\n",
    "        return(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When writing this code, we run into a few errors: \n",
    "Creating different scenarios for the method alorithm when we include the true solution in our input lead to some issues, and had to use the code \"type(true) == np.ndarray\" which was not clear at first. \n",
    "\n",
    "At first, John tried to use matrix multiplication when multiplying by d inverse (like is done in the mathmatical algoritm), however, d is stored as an array in our code and because of vectorized nature of numpy, the solution was to just use the normal multiplication operator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Algorithm\n",
    "\n",
    "- Example from HW 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations = 35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99999991, 0.99999982, 0.99999974, 0.99999966, 0.99999959,\n",
       "       0.99999953, 0.99999948, 0.99999943, 0.9999994 , 0.99999937,\n",
       "       0.99999936, 0.99999934, 0.99999933, 0.99999932, 0.99999932,\n",
       "       0.99999932, 0.99999932, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999931, 0.99999931,\n",
       "       0.99999931, 0.99999931, 0.99999931, 0.99999932, 0.99999932,\n",
       "       0.99999932, 0.99999932, 0.99999933, 0.99999934, 0.99999936,\n",
       "       0.99999937, 0.9999994 , 0.99999943, 0.99999948, 0.99999953,\n",
       "       0.99999959, 0.99999966, 0.99999974, 0.99999982, 0.99999991])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = np.diag(-np.ones(99), -1)\n",
    "U = np.diag(-np.ones(99), 1)\n",
    "d = np.diag(3*np.ones(100))\n",
    "A = L + U + d\n",
    "b = np.array([2] + [1]*98 + [2])\n",
    "x = jacobi(A, b, np.zeros(100), tol = 0.000001, true = np.ones(100))\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm written by Chat GPT 3.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_GPT(A, b, x0, tol=1e-6, max_iter=1000):\n",
    "    n = len(b)\n",
    "    x = np.array(x0, dtype=float)\n",
    "    x_new = np.zeros_like(x)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        for i in range(n):\n",
    "            sum_ = np.dot(A[i, :i], x[:i]) + np.dot(A[i, i+1:], x[i+1:])\n",
    "            x_new[i] = (b[i] - sum_) / A[i, i]\n",
    "        \n",
    "        if np.linalg.norm(x_new - x) < tol:\n",
    "            return x_new\n",
    "        \n",
    "        x = np.copy(x_new)\n",
    "    \n",
    "    raise ValueError(\"Jacobi method did not converge within the maximum number of iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Chat gpts code stops the alorithm when the difference between the new value and the last value is less than a certain amount, which is different than our code which uses a set number of iterations (or requires the solution which is helpful for testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Chat GPT's code with the same example from HW 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999997 0.99999995 0.99999992 0.9999999  0.99999988 0.99999987\n",
      " 0.99999985 0.99999984 0.99999983 0.99999982 0.99999981 0.99999981\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.9999998  0.9999998\n",
      " 0.9999998  0.9999998  0.9999998  0.9999998  0.99999981 0.99999981\n",
      " 0.99999982 0.99999983 0.99999984 0.99999985 0.99999987 0.99999988\n",
      " 0.9999999  0.99999992 0.99999995 0.99999997]\n",
      "4.832771325347096e-07\n"
     ]
    }
   ],
   "source": [
    "L = np.diag(-np.ones(99), -1)\n",
    "U = np.diag(-np.ones(99), 1)\n",
    "d = np.diag(3*np.ones(100))\n",
    "A = L + U + d\n",
    "b = np.array([2] + [1]*98 + [2])\n",
    "x_GPT = jacobi_GPT(A, b, np.zeros(100), tol = 0.000001)\n",
    "print(x_GPT)\n",
    "print(max(abs(x_GPT - x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GPT 3.5 code produced a result extremely close to the result of our code. Asking Chat GPT to write the code took about 2 minutes, whereas the code we wrote took about an hour with trial and error being required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999997 1.99999994 0.99999997]\n",
      "[0.99999905 1.99999905 0.99999905]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]])\n",
    "b = np.array([0, 2, 0])\n",
    "x = jacobi(A, b, np.zeros(3))\n",
    "print(x)\n",
    "x_gpt = jacobi_GPT(A, b, np.zeros(3))\n",
    "print(x_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is another example from HW 3\n",
    "\n",
    "- Both of the functions produced results close to the true solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent Method By Zhenyuan Ni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum at: [4.01734511e-06 4.01734511e-06]\n",
      "Minimum at: [ 1.23023192e-97  4.93986584e+41 -6.29828712e+29  4.07127679e+30\n",
      " -2.35055275e+30]\n",
      "1.4167495700510191e+121\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def gradient_descent(gradient, start, learn_rate, n_iterations, tolerance):\n",
    "    vector = start\n",
    "    for _ in range(n_iterations):\n",
    "        diff = -learn_rate * gradient(vector)\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "        vector += diff\n",
    "    return vector\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# Define the gradient of your function here\n",
    "def gradient_function(v):\n",
    "    # Example for a 2D function: f(x, y) = x^2 + y^2\n",
    "    return np.array([2 * v[0], 2 * v[1]])\n",
    "\n",
    "\n",
    "# Starting point (can be any point in your domain)\n",
    "start_point = np.array([10.0, 10.0])\n",
    "\n",
    "# Learning rate\n",
    "learn_rate = 0.1\n",
    "\n",
    "# Number of iterations\n",
    "n_iterations = 1000\n",
    "\n",
    "# Tolerance for stopping criterion\n",
    "tolerance = 1e-6\n",
    "\n",
    "minimum = gradient_descent(gradient_function, start_point, learn_rate, n_iterations, tolerance)\n",
    "print(\"Minimum at:\", minimum)\n",
    "\n",
    "\n",
    "# Multivariable case\n",
    "def func(v):\n",
    "    return v[0]**2 - v[1] * v[2]**2 + v[2] * v[3] * v[4]**2\n",
    "\n",
    "\n",
    "def gradient_function1(v):\n",
    "    # Example for a 2D function: f(x, y) = x1^2 - x2 * x3^2 + x3 * x4 * x5^2\n",
    "    return np.array([2 * v[0], -v[1], 2*v[2] + v[3] + v[4], v[2] + v[4], v[3] + v[4]])\n",
    "\n",
    "\n",
    "start_point = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "minimum = gradient_descent(gradient_function1, start_point, learn_rate, n_iterations, tolerance)\n",
    "print(\"Minimum at:\", minimum)\n",
    "ylist = []\n",
    "for x1 in range(10):\n",
    "    for x2 in range(10):\n",
    "        for x3 in range(10):\n",
    "            for x4 in range(10):\n",
    "                for x5 in range(10):\n",
    "                    ylist.append(func([1 + 0.1 * x1, 4 + 0.1 * x2, -6 + 0.1 * x3, 4 + 0.1 * x4, -2 + 0.1 * x5]))\n",
    "miny = np.min(ylist) - func(minimum)\n",
    "print(miny)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatgpt 3.5 Gradient Descent method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat Gpt notes that a common optimization for better efficiency is to use vectorized coding instead:\n",
    "\n",
    "- One common optimization is to use vectorized operations whenever possible to leverage the computational efficiency of NumPy. \n",
    "- Additionally, we can adjust the step size dynamically during optimization to improve convergence. \n",
    "\n",
    "Here's the optimized version of the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum at: [1.20459505 1.20459505]\n",
      "Minimum at: [0.12045854        nan        nan        nan        nan]\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xh/4xpwy9dj7glg3lpzyn0wwqgw0000gn/T/ipykernel_4675/1267282877.py:43: RuntimeWarning: overflow encountered in scalar power\n",
      "  grad[1] = -v[2]**2\n",
      "/var/folders/xh/4xpwy9dj7glg3lpzyn0wwqgw0000gn/T/ipykernel_4675/1267282877.py:44: RuntimeWarning: overflow encountered in scalar power\n",
      "  grad[2] = -2 * v[1] * v[2] + v[3] * v[4]**2\n",
      "/var/folders/xh/4xpwy9dj7glg3lpzyn0wwqgw0000gn/T/ipykernel_4675/1267282877.py:45: RuntimeWarning: overflow encountered in scalar power\n",
      "  grad[3] = v[2] * v[4]**2\n",
      "/var/folders/xh/4xpwy9dj7glg3lpzyn0wwqgw0000gn/T/ipykernel_4675/1267282877.py:46: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  grad[4] = 2 * v[2] * v[3] * v[4]\n",
      "/var/folders/xh/4xpwy9dj7glg3lpzyn0wwqgw0000gn/T/ipykernel_4675/1267282877.py:44: RuntimeWarning: invalid value encountered in scalar add\n",
      "  grad[2] = -2 * v[1] * v[2] + v[3] * v[4]**2\n",
      "/var/folders/xh/4xpwy9dj7glg3lpzyn0wwqgw0000gn/T/ipykernel_4675/1267282877.py:9: RuntimeWarning: invalid value encountered in add\n",
      "  vector += diff\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_descent(gradient, start, learn_rate, n_iterations, tolerance):\n",
    "    vector = start\n",
    "    for _ in range(n_iterations):\n",
    "        diff = -learn_rate * gradient(vector)\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "        vector += diff\n",
    "        # Adjust learning rate dynamically\n",
    "        learn_rate *= 0.9  # or any other suitable decay factor\n",
    "    return vector\n",
    "\n",
    "# Example usage\n",
    "# Define the gradient of your function here\n",
    "def gradient_function(v):\n",
    "    # Example for a 2D function: f(x, y) = x^2 + y^2\n",
    "    return np.array([2 * v[0], 2 * v[1]])\n",
    "\n",
    "# Starting point (can be any point in your domain)\n",
    "start_point = np.array([10.0, 10.0])\n",
    "\n",
    "# Learning rate\n",
    "learn_rate = 0.1\n",
    "\n",
    "# Number of iterations\n",
    "n_iterations = 1000\n",
    "\n",
    "# Tolerance for stopping criterion\n",
    "tolerance = 1e-6\n",
    "\n",
    "minimum = gradient_descent(gradient_function, start_point, learn_rate, n_iterations, tolerance)\n",
    "print(\"Minimum at:\", minimum)\n",
    "\n",
    "# Multivariable case\n",
    "def func(v):\n",
    "    return v[0]**2 - v[1] * v[2]**2 + v[2] * v[3] * v[4]**2\n",
    "\n",
    "def gradient_function1(v):\n",
    "    # Gradient of the function f(v) = v[0]^2 - v[1] * v[2]^2 + v[2] * v[3] * v[4]^2\n",
    "    grad = np.zeros_like(v)\n",
    "    grad[0] = 2 * v[0]\n",
    "    grad[1] = -v[2]**2\n",
    "    grad[2] = -2 * v[1] * v[2] + v[3] * v[4]**2\n",
    "    grad[3] = v[2] * v[4]**2\n",
    "    grad[4] = 2 * v[2] * v[3] * v[4]\n",
    "    return grad\n",
    "\n",
    "\n",
    "start_point = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "minimum = gradient_descent(gradient_function1, start_point, learn_rate, n_iterations, tolerance)\n",
    "print(\"Minimum at:\", minimum)\n",
    "\n",
    "# No need to search for minimum manually\n",
    "# Minimum value can be calculated directly from the function\n",
    "miny = func(minimum)\n",
    "print(miny)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there was an overflow issue with the results in the code. This is primarily due to:\n",
    "\n",
    "- the gradient vector was properly updated, and for multivariate cases we see this is an issue that can arise for wrong initial guesses, \n",
    "- The need to change hyperparameters (learning rate, iterations etc.)\n",
    "\n",
    "This can be explored more so in another course but this is very interesting to see what can cause runtime warnings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally is Reese's RK4 method coupled with the Rossler and Chen Attractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "def rossler(xyz, a=0.1, b=0.1, c=14):\n",
    "    \"\"\"\n",
    "    Defines the Rossler attractor.\n",
    "\n",
    "    Parameters:\n",
    "    - xyz: A tuple or list of current [x, y, z] coordinates.\n",
    "    - a, b, c: Parameters that define the behavior of the attractor.\n",
    "\n",
    "    Returns:\n",
    "    - An array of derivatives [dx, dy, dz].\n",
    "    \"\"\"\n",
    "    x, y, z = xyz\n",
    "    dx = -y - z\n",
    "    dy = x + a * y\n",
    "    dz = b + z * (x - c)\n",
    "    return np.array([dx, dy, dz])\n",
    "\n",
    "def Chen(xyz, a=5, b=-10, c=-0.38):\n",
    "    \"\"\"\n",
    "    Defines the Chen attractor.\n",
    "\n",
    "    Parameters:\n",
    "    - xyz: A tuple or list of current [x, y, z] coordinates.\n",
    "    - a, b, c: Parameters that define the behavior of the attractor.\n",
    "\n",
    "    Returns:\n",
    "    - An array of derivatives [dx, dy, dz].\n",
    "    \"\"\"\n",
    "    x, y, z = xyz\n",
    "    dx = a * x - y * z\n",
    "    dy = b * y + x * z\n",
    "    dz = c * z + (x * y) / 3\n",
    "    return np.array([dx, dy, dz])\n",
    "\n",
    "def Runge_kutta_4(f: Callable, x0: float, y0: float, z0: float, h: float, TT: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Implements the fourth-order Runge-Kutta method for solving ODEs.\n",
    "\n",
    "    Parameters:\n",
    "    - f: The function representing the ODE system (e.g., rossler, Chen).\n",
    "    - x0, y0, z0: Initial conditions for the ODE system.\n",
    "    - h: Step size.\n",
    "    - TT: Total time for which the solution is computed.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array containing the solution at each time step.\n",
    "    \"\"\"\n",
    "    initial_conditions = [x0, y0, z0]\n",
    "    time_start, time_end = 0, TT\n",
    "    num_steps = int((time_end - time_start) / h)\n",
    "\n",
    "    xyz = np.zeros((num_steps, 3))\n",
    "    xyz[0, :] = initial_conditions\n",
    "\n",
    "    for i in range(num_steps-1):\n",
    "        # Calculate the four increments\n",
    "        k1 = h * f(xyz[i, :])\n",
    "        k2 = h * f(xyz[i, :] + 0.5 * k1)\n",
    "        k3 = h * f(xyz[i, :] + 0.5 * k2)\n",
    "        k4 = h * f(xyz[i, :] + h * k3)\n",
    "        # Update the solution\n",
    "        xyz[i + 1, :] = xyz[i, :] + (1 / 6) * (k1 + 2 * k2 + 2 * k3 + k4)\n",
    "\n",
    "    return xyz\n",
    "\n",
    "\n",
    "# initial conditions\n",
    "### Rossler\n",
    "x0, y0, z0 = 0, 1, 0\n",
    "\n",
    "### Chen\n",
    "x1,y1,z1 = 5,10,10\n",
    "x2,y2,z2 = -7,-5,-10\n",
    "\n",
    "\n",
    "trajectory_rossler = Runge_kutta_4(rossler, x0=x0, y0=y0, z0=z0, h=0.01, TT=500)\n",
    "trajectory_Chen1 = Runge_kutta_4(Chen, x0=x1, y0=y1, z0=z1, h=0.01, TT = 1000)\n",
    "trajectory_Chen2 = Runge_kutta_4(Chen, x0=x2, y0=y2, z0=z2, h=0.01, TT = 1000)\n",
    "\n",
    "\n",
    "### Plotting the trajctory\n",
    "\n",
    "# [Assuming 'trajectory_rossler', 'trajectory_Chen1', and 'trajectory_Chen2' are already computed]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(27, 16), subplot_kw={'projection': '3d'})\n",
    "\n",
    "# Plotting the Rossler trajectory\n",
    "axs[0].plot(trajectory_rossler[:, 0], trajectory_rossler[:, 1], trajectory_rossler[:, 2], color=\"blue\", label=\"Rossler Attractor\")\n",
    "axs[0].set_xlabel('X axis')\n",
    "axs[0].set_ylabel('Y axis')\n",
    "axs[0].set_zlabel('Z axis')\n",
    "axs[0].set_title('Rossler Attractor')\n",
    "axs[0].legend()  # Adding legend to the first subplot\n",
    "\n",
    "# Plotting the Chen trajectories\n",
    "axs[1].plot(trajectory_Chen1[:, 0], trajectory_Chen1[:, 1], trajectory_Chen1[:, 2], color=\"green\", label=\"Chen1 Attractor\")\n",
    "axs[1].plot(trajectory_Chen2[:, 0], trajectory_Chen2[:, 1], trajectory_Chen2[:, 2], color=\"purple\", label=\"Chen2 Attractor\")\n",
    "axs[1].set_xlabel('X axis')\n",
    "axs[1].set_ylabel('Y axis')\n",
    "axs[1].set_zlabel('Z axis')\n",
    "axs[1].set_title('Chen Attractor')\n",
    "axs[1].legend()  # Adding legend to the second subplot\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat GPT 4.0 model building a similar script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def rk4_step(f, x, t, dt):\n",
    "    \"\"\"\n",
    "    Perform a single step of the RK4 method.\n",
    "    \"\"\"\n",
    "    k1 = f(x, t)\n",
    "    k2 = f(x + 0.5 * k1 * dt, t + 0.5 * dt)\n",
    "    k3 = f(x + 0.5 * k2 * dt, t + 0.5 * dt)\n",
    "    k4 = f(x + k3 * dt, t + dt)\n",
    "    return x + (dt / 6) * (k1 + 2*k2 + 2*k3 + k4)\n",
    "\n",
    "def rk4(f, x0, t0, tf, dt):\n",
    "    \"\"\"\n",
    "    Run the RK4 method for a system of ODEs.\n",
    "    \"\"\"\n",
    "    t = np.arange(t0, tf, dt)\n",
    "    x = np.zeros((len(t), len(x0)))\n",
    "    x[0] = x0\n",
    "    for i in range(1, len(t)):\n",
    "        x[i] = rk4_step(f, x[i-1], t[i-1], dt)\n",
    "    return t, x\n",
    "\n",
    "# Rossler attractor\n",
    "def rossler_attractor(x, t):\n",
    "    a, b, c = 0.2, 0.2, 5.7\n",
    "    dxdt = -x[1] - x[2]\n",
    "    dydt = x[0] + a*x[1]\n",
    "    dzdt = b + x[2]*(x[0] - c)\n",
    "    return np.array([dxdt, dydt, dzdt])\n",
    "\n",
    "# Chen attractor\n",
    "def chen_attractor(x, t):\n",
    "    a, b, c = 35, 3, 28\n",
    "    dxdt = a*(x[1] - x[0])\n",
    "    dydt = (c - a)*x[0] - x[0]*x[2] + c*x[1]\n",
    "    dzdt = x[0]*x[1] - b*x[2]\n",
    "    return np.array([dxdt, dydt, dzdt])\n",
    "\n",
    "# Initial conditions\n",
    "rossler_initial = np.array([0, 1, 0])  # Rossler\n",
    "chen_initial_1 = np.array([5, 10, 10])  # Chen 1\n",
    "chen_initial_2 = np.array([-7, -5, -10])  # Chen 2\n",
    "\n",
    "# Time span\n",
    "t0, tf, dt = 0, 100, 0.01\n",
    "\n",
    "# Simulate\n",
    "t, rossler_solution = rk4(rossler_attractor, rossler_initial, t0, tf, dt)\n",
    "_, chen_solution_1 = rk4(chen_attractor, chen_initial_1, t0, tf, dt)\n",
    "_, chen_solution_2 = rk4(chen_attractor, chen_initial_2, t0, tf, dt)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "# Rossler Attractor\n",
    "axs[0].plot(rossler_solution[:, 0], rossler_solution[:, 1])\n",
    "axs[0].set_title('Rossler Attractor')\n",
    "\n",
    "# Chen Attractor Initial Condition 1\n",
    "axs[1].plot(chen_solution_1[:, 0], chen_solution_1[:, 1])\n",
    "axs[1].set_title('Chen Attractor Initial Condition 1')\n",
    "\n",
    "# Chen Attractor Initial Condition 2\n",
    "axs[2].plot(chen_solution_2[:, 0], chen_solution_2[:, 1])\n",
    "axs[2].set_title('Chen Attractor Initial Condition 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This roughly took around 1 min to build from the chat gpt 4.0 model, with this request:\n",
    "Can you build me a script that can perform rk4 method with the rossler and Chen attractor with these initial conditions:\n",
    "\n",
    "initial conditions: \n",
    "Rossler: \n",
    "x0, y0, z0 = 0, 1, 0\n",
    "\n",
    "Chen: \n",
    "x1,y1,z1 = 5,10,10\n",
    "x2,y2,z2 = -7,-5,-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat GPT 3.5 turbo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the Rossler attractor equations\n",
    "def rossler(x, y, z, a=0.2, b=0.2, c=5.7):\n",
    "    dx = -y - z\n",
    "    dy = x + a * y\n",
    "    dz = b + z * (x - c)\n",
    "    return dx, dy, dz\n",
    "\n",
    "# Define the Chen attractor equations\n",
    "def chen(x, y, z, a=35, b=3, c=28):\n",
    "    dx = a * (y - x)\n",
    "    dy = (c - a) * x - x * z + c * y\n",
    "    dz = x * y - b * z\n",
    "    return dx, dy, dz\n",
    "\n",
    "# Define the RK4 method for solving differential equations\n",
    "def rk4_step(func, x, y, z, h):\n",
    "    k1x, k1y, k1z = func(x, y, z)\n",
    "    k2x, k2y, k2z = func(x + 0.5 * h * k1x, y + 0.5 * h * k1y, z + 0.5 * h * k1z)\n",
    "    k3x, k3y, k3z = func(x + 0.5 * h * k2x, y + 0.5 * h * k2y, z + 0.5 * h * k2z)\n",
    "    k4x, k4y, k4z = func(x + h * k3x, y + h * k3y, z + h * k3z)\n",
    "    x_new = x + (h / 6.0) * (k1x + 2 * k2x + 2 * k3x + k4x)\n",
    "    y_new = y + (h / 6.0) * (k1y + 2 * k2y + 2 * k3y + k4y)\n",
    "    z_new = z + (h / 6.0) * (k1z + 2 * k2z + 2 * k3z + k4z)\n",
    "    return x_new, y_new, z_new\n",
    "\n",
    "# Parameters for numerical integration\n",
    "t_max = 1000\n",
    "dt = 0.01\n",
    "num_steps = int(t_max / dt)\n",
    "\n",
    "# Initial conditions for Rossler attractor\n",
    "x0, y0, z0 = 0, 1, 0\n",
    "\n",
    "# Arrays to store the solution\n",
    "rossler_solution = np.zeros((num_steps, 3))\n",
    "rossler_solution[0] = [x0, y0, z0]\n",
    "\n",
    "# Perform numerical integration for Rossler attractor\n",
    "for i in range(1, num_steps):\n",
    "    x, y, z = rk4_step(rossler, rossler_solution[i - 1, 0], rossler_solution[i - 1, 1], rossler_solution[i - 1, 2], dt)\n",
    "    rossler_solution[i] = [x, y, z]\n",
    "\n",
    "# Plot Rossler attractor\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(rossler_solution[:, 0], rossler_solution[:, 1], rossler_solution[:, 2], color='b')\n",
    "ax.set_title('Rossler Attractor')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "plt.show()\n",
    "\n",
    "# Initial conditions for Chen attractor\n",
    "x1, y1, z1 = 5, 10, 10\n",
    "x2, y2, z2 = -7, -5, -10\n",
    "\n",
    "# Arrays to store the solution\n",
    "chen_solution1 = np.zeros((num_steps, 3))\n",
    "chen_solution1[0] = [x1, y1, z1]\n",
    "chen_solution2 = np.zeros((num_steps, 3))\n",
    "chen_solution2[0] = [x2, y2, z2]\n",
    "\n",
    "# Perform numerical integration for Chen attractor\n",
    "for i in range(1, num_steps):\n",
    "    x1, y1, z1 = rk4_step(chen, chen_solution1[i - 1, 0], chen_solution1[i - 1, 1], chen_solution1[i - 1, 2], dt)\n",
    "    chen_solution1[i] = [x1, y1, z1]\n",
    "    x2, y2, z2 = rk4_step(chen, chen_solution2[i - 1, 0], chen_solution2[i - 1, 1], chen_solution2[i - 1, 2], dt)\n",
    "    chen_solution2[i] = [x2, y2, z2]\n",
    "\n",
    "# Plot Chen attractor\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(chen_solution1[:, 0], chen_solution1[:, 1], chen_solution1[:, 2], color='r', label='Chen Attractor 1')\n",
    "ax.plot(chen_solution2[:, 0], chen_solution2[:, 1], chen_solution2[:, 2], color='g', label='Chen Attractor 2')\n",
    "ax.set_title('Chen Attractor')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
